{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aba5798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32274de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  \n",
      "0                          3.92   1065.0  \n",
      "1                          3.40   1050.0  \n",
      "2                          3.17   1185.0  \n",
      "3                          3.45   1480.0  \n",
      "4                          2.93    735.0  \n",
      "(178, 13)\n",
      "/n\n",
      "Target Names (Classes): ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "data = load_wine()\n",
    "wine_df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "print(wine_df.head(), wine_df.shape, sep='\\n')\n",
    "print(\"/n\")\n",
    "\n",
    "print(\"Target Names (Classes):\", data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2df31f",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fa58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.data\n",
    "y = data.target # type of wine class 0 , 1, 2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5ba61",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ec12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_decision_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "classifier_decision_tree.fit(x_train, y_train)\n",
    "y_pred_decision_tree = classifier_decision_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c79ed43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_decision_tree = f1_score(y_test, y_pred_decision_tree, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf09a87",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5ac0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_random_forest = RandomForestClassifier(n_estimators=100, random_state=12)\n",
    "classifier_random_forest.fit(x_train, y_train)\n",
    "y_pred_random_forest = classifier_random_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96deae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_random_forest = f1_score(y_test, y_pred_random_forest, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18d37a6",
   "metadata": {},
   "source": [
    "## F1-Score Comparision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695b1431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier F1 Score: 0.9449\n",
      "Random forest classifier F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Decision tree classifier F1 Score: {f1_decision_tree:.4f}\")\n",
    "print(f\"Random forest classifier F1 Score: {f1_random_forest:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2415990",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using GridSearchCV, Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "559bb0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best F1 Score: 0.9790\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=classifier_random_forest,\n",
    "    param_grid={\n",
    "        \"n_estimators\": [50, 100, 200, 500],\n",
    "        \"max_depth\": [3, 5, 10],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    },\n",
    "    scoring=\"f1_weighted\",\n",
    "    cv=4,\n",
    ")\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best F1 Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b773c91",
   "metadata": {},
   "source": [
    "# Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44bec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "158        1.68  2.70               25.0       98.0           2.80   \n",
      "137        5.51  2.64               25.0       96.0           1.79   \n",
      "98         1.07  2.10               18.5       88.0           3.52   \n",
      "159        1.67  2.64               22.5       89.0           2.60   \n",
      "38         1.50  2.10               15.5       98.0           2.40   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "158        1.31                  0.53             2.70            13.00  0.57   \n",
      "137        0.60                  0.63             1.10             5.00  0.82   \n",
      "98         3.75                  0.24             1.95             4.50  1.04   \n",
      "159        1.10                  0.52             2.29            11.75  0.57   \n",
      "38         2.64                  0.28             1.37             3.70  1.18   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  \n",
      "158                          1.96    660.0  \n",
      "137                          1.69    515.0  \n",
      "98                           2.77    660.0  \n",
      "159                          1.78    620.0  \n",
      "38                           2.69   1020.0  \n",
      "158    14.34\n",
      "137    12.53\n",
      "98     12.37\n",
      "159    13.48\n",
      "38     13.07\n",
      "Name: alcohol, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x2 = wine_df.drop(columns=[\"alcohol\"]) \n",
    "y2 = wine_df[\"alcohol\"]  # \"Alcohol\" as the target\n",
    "\n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(\n",
    "    x2, y2, test_size=0.2, random_state=42\n",
    ")\n",
    "print(x_train_2.head())  # Features\n",
    "print(y_train_2.head())  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571941e",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2e19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_decision_tree = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "regressor_decision_tree.fit(x_train_2, y_train_2)\n",
    "y_pred_decision_tree_regressor = regressor_decision_tree.predict(x_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ca753",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf86338",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor_random_forest.fit(x_train_2, y_train_2)\n",
    "y_pred_random_forest_regressor = regressor_random_forest.predict(x_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18e2ab",
   "metadata": {},
   "source": [
    "## Mean-Squared Error Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e1584ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor MSE: 0.2913\n",
      "Random Forest Regressor MSE: 0.1542\n",
      "\n",
      "\n",
      "mse of decision tree regressor is greater\n"
     ]
    }
   ],
   "source": [
    "mse_dt = mean_squared_error(y_test_2, y_pred_decision_tree_regressor)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test_2, y_pred_random_forest_regressor)\n",
    "\n",
    "print(f\"Decision Tree Regressor MSE: {mse_dt:.4f}\")\n",
    "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "if (mse_dt > mse_rf):\n",
    "    print(\"mse of decision tree regressor is greater\")\n",
    "else:\n",
    "    print(\"Mse of random forest regressor is greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976fb1bb",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using RandomizedSearchCV, Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06da9390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 5, 'max_features': 'log2', 'max_depth': 10}\n",
      "Best Negative MSE Score: -0.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "90 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [        nan -0.32262256         nan -0.31328779 -0.31367275 -0.33006015\n",
      " -0.30575645 -0.31366482 -0.30861169 -0.31944649 -0.30746197         nan\n",
      " -0.30815325 -0.31431827 -0.3027272  -0.30726006 -0.32143784 -0.31940453\n",
      " -0.31840501         nan         nan         nan         nan         nan\n",
      " -0.31023194         nan         nan         nan -0.32048089 -0.30631924\n",
      " -0.32262256 -0.30831627         nan -0.32470014         nan -0.3111255\n",
      "         nan         nan         nan -0.30714445 -0.30905085 -0.3077383\n",
      "         nan -0.30905085 -0.32470014         nan -0.30831627 -0.33006015\n",
      " -0.32897348 -0.3209527 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=regressor_random_forest,\n",
    "    param_distributions={\n",
    "        \"n_estimators\": [50, 100, 200, 300],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "    },\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    ")\n",
    "random_search.fit(x_train_2, y_train_2)\n",
    "\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Best Negative MSE Score: {random_search.best_score_:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
